{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation different embedding methods\n",
    "### 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import config as cfg\n",
    "import benchmark_common as bcommon\n",
    "import benchmark_train as btrain\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tools.funclib as funclib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 loading task data\n"
     ]
    }
   ],
   "source": [
    "print('step 1 loading task data')\n",
    "data_task1_train = pd.read_feather(cfg.FILE_TASK1_TRAIN)\n",
    "data_task1_test_2020 = pd.read_feather(cfg.FILE_TASK1_TEST_2020)\n",
    "data_task1_test_2022 = pd.read_feather(cfg.FILE_TASK1_TEST_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2: Loading features, embdding method=esm32\n",
      "step 3: train isEnzyme model\n",
      "knn \t\t0.922546 \t0.936865 \t\t0.911117 \t0.893765 \t0.914808 \t tp: 2953 fp: 199 fn: 351 tn: 3598\n",
      "knn \t\t0.917656 \t0.938159 \t\t0.900502 \t0.887498 \t0.912125 \t tp: 4536 fp: 299 fn: 575 tn: 5204\n"
     ]
    }
   ],
   "source": [
    "embd_method = 'esm32'\n",
    "print(f'step 2: Loading features, embdding method={embd_method}')\n",
    "feature_df = bcommon.load_data_embedding(embedding_type=embd_method)\n",
    "\n",
    "print('step 3: train isEnzyme model')\n",
    "task1_train_X, task1_train_Y = btrain.get_train_X_Y(traindata=data_task1_train, feature_bankfile=feature_df, task=1)\n",
    "task1_test_X_2020, task1_test_Y_2020 = btrain.get_train_X_Y(traindata=data_task1_test_2020, feature_bankfile=feature_df, task=1)\n",
    "task1_test_X_2022, task1_test_Y_2022 = btrain.get_train_X_Y(traindata=data_task1_test_2022, feature_bankfile=feature_df, task=1)\n",
    "\n",
    "t1_x_train, t1_x_vali, t1_y_train, t1_y_vali = train_test_split(task1_train_X,np.array(task1_train_Y).ravel(),test_size=cfg.VALIDATION_RATE,random_state=1)\n",
    "# t1_eval_set = [(t1_x_train, t1_y_train), (t1_x_vali, t1_y_vali), (task1_test_X_2020, task1_test_Y_2020)]\n",
    "\n",
    "# methods=['knn','lr', 'xg', 'dt', 'rf', 'gbdt']\n",
    "# # methods=['xg', 'dt', 'rf', 'gbdt']\n",
    "# for method in methods:\n",
    "#     funclib.evaluate_2(baslineName=method, X_train_std=t1_x_train, Y_train=t1_y_train, X_test_std=task1_test_X, Y_test=task1_test_Y, type='binary')\n",
    "\n",
    "funclib.evaluate_2(baslineName='knn', X_train_std=t1_x_train, Y_train=t1_y_train, X_test_std=task1_test_X_2020, Y_test=task1_test_Y_2020, type='binary')\n",
    "funclib.evaluate_2(baslineName='knn', X_train_std=t1_x_train, Y_train=t1_y_train, X_test_std=task1_test_X_2022, Y_test=task1_test_Y_2022, type='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2: Loading features, embdding method=unirep\n",
      "step 3: train isEnzyme model\n",
      "knn \t\t0.882325 \t0.889943 \t\t0.875662 \t0.862258 \t0.875882 \t tp: 4407 fp: 545 fn: 704 tn: 4958\n",
      "lr \t\t0.869324 \t0.899914 \t\t0.845418 \t0.819800 \t0.857991 \t tp: 4190 fp: 466 fn: 921 tn: 5037\n",
      "xg \t\t0.866403 \t0.914664 \t\t0.831521 \t0.796909 \t0.851736 \t tp: 4073 fp: 380 fn: 1038 tn: 5123\n",
      "dt \t\t0.819013 \t0.849781 \t\t0.795837 \t0.758169 \t0.801365 \t tp: 3875 fp: 685 fn: 1236 tn: 4818\n",
      "rf \t\t0.887319 \t0.933747 \t\t0.852975 \t0.824496 \t0.875727 \t tp: 4214 fp: 299 fn: 897 tn: 5204\n",
      "gbdt \t\t0.857076 \t0.911778 \t\t0.818880 \t0.778517 \t0.839894 \t tp: 3979 fp: 385 fn: 1132 tn: 5118\n",
      "step 2: Loading features, embdding method=esm0\n",
      "step 3: train isEnzyme model\n",
      "knn \t\t0.812983 \t0.797148 \t\t0.828539 \t0.820387 \t0.808601 \t tp: 4193 fp: 1067 fn: 918 tn: 4436\n",
      "lr \t\t0.760693 \t0.751320 \t\t0.769413 \t0.751908 \t0.751614 \t tp: 3843 fp: 1272 fn: 1268 tn: 4231\n",
      "xg \t\t0.819861 \t0.827565 \t\t0.813296 \t0.790648 \t0.808685 \t tp: 4041 fp: 842 fn: 1070 tn: 4661\n",
      "dt \t\t0.748634 \t0.752324 \t\t0.745540 \t0.712581 \t0.731913 \t tp: 3642 fp: 1199 fn: 1469 tn: 4304\n",
      "rf \t\t0.840682 \t0.868534 \t\t0.819049 \t0.788495 \t0.826582 \t tp: 4030 fp: 610 fn: 1081 tn: 4893\n",
      "gbdt \t\t0.823347 \t0.826737 \t\t0.820381 \t0.801017 \t0.813674 \t tp: 4094 fp: 858 fn: 1017 tn: 4645\n",
      "step 2: Loading features, embdding method=esm33\n",
      "step 3: train isEnzyme model\n",
      "knn \t\t0.917939 \t0.937474 \t\t0.901526 \t0.888867 \t0.912524 \t tp: 4543 fp: 303 fn: 568 tn: 5200\n",
      "lr \t\t0.904372 \t0.929710 \t\t0.883721 \t0.866954 \t0.897236 \t tp: 4431 fp: 335 fn: 680 tn: 5168\n",
      "xg \t\t0.876767 \t0.914180 \t\t0.848248 \t0.821170 \t0.865182 \t tp: 4197 fp: 394 fn: 914 tn: 5109\n",
      "dt \t\t0.810910 \t0.839309 \t\t0.789404 \t0.751125 \t0.792772 \t tp: 3839 fp: 735 fn: 1272 tn: 4768\n",
      "rf \t\t0.904372 \t0.963139 \t\t0.862403 \t0.833301 \t0.893528 \t tp: 4259 fp: 163 fn: 852 tn: 5340\n",
      "gbdt \t\t0.869700 \t0.913671 \t\t0.837263 \t0.805518 \t0.856192 \t tp: 4117 fp: 389 fn: 994 tn: 5114\n",
      "step 2: Loading features, embdding method=one-hot\n",
      "step 3: train isEnzyme model\n",
      "knn \t\t0.532787 \t0.726190 \t\t0.526464 \t0.047740 \t0.089591 \t tp: 244 fp: 92 fn: 4867 tn: 5411\n",
      "lr \t\t0.657999 \t0.635152 \t\t0.682376 \t0.680884 \t0.657224 \t tp: 3480 fp: 1999 fn: 1631 tn: 3504\n",
      "xg \t\t0.633786 \t0.660042 \t\t0.618999 \t0.493837 \t0.564969 \t tp: 2524 fp: 1300 fn: 2587 tn: 4203\n",
      "dt \t\t0.605804 \t0.602658 \t\t0.608132 \t0.532381 \t0.565344 \t tp: 2721 fp: 1794 fn: 2390 tn: 3709\n",
      "rf \t\t0.657434 \t0.688860 \t\t0.639141 \t0.526316 \t0.596717 \t tp: 2690 fp: 1215 fn: 2421 tn: 4288\n",
      "gbdt \t\t0.638496 \t0.656127 \t\t0.627487 \t0.523772 \t0.582526 \t tp: 2677 fp: 1403 fn: 2434 tn: 4100\n",
      "step 2: Loading features, embdding method=esm32\n",
      "step 3: train isEnzyme model\n",
      "knn \t\t0.917656 \t0.938159 \t\t0.900502 \t0.887498 \t0.912125 \t tp: 4536 fp: 299 fn: 575 tn: 5204\n",
      "lr \t\t0.907386 \t0.928394 \t\t0.889924 \t0.875171 \t0.900997 \t tp: 4473 fp: 345 fn: 638 tn: 5158\n",
      "xg \t\t0.878557 \t0.922788 \t\t0.845750 \t0.816083 \t0.866161 \t tp: 4171 fp: 349 fn: 940 tn: 5154\n",
      "dt \t\t0.821839 \t0.852606 \t\t0.798611 \t0.761690 \t0.804588 \t tp: 3893 fp: 673 fn: 1218 tn: 4830\n",
      "rf \t\t0.903335 \t0.964099 \t\t0.860293 \t0.830170 \t0.892136 \t tp: 4243 fp: 158 fn: 868 tn: 5345\n",
      "gbdt \t\t0.874882 \t0.915440 \t\t0.844415 \t0.815496 \t0.862583 \t tp: 4168 fp: 385 fn: 943 tn: 5118\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_METHODs = ['unirep', 'esm0', 'esm33', 'one-hot' , 'esm32']\n",
    "for embd_method in EMBEDDING_METHODs:\n",
    "    print(f'step 2: Loading features, embdding method={embd_method}')\n",
    "    feature_df = bcommon.load_data_embedding(embedding_type=embd_method)\n",
    "\n",
    "    print('step 3: train isEnzyme model')\n",
    "    task1_train_X, task1_train_Y = btrain.get_train_X_Y(traindata=data_task1_train, feature_bankfile=feature_df, task=1)\n",
    "    task1_test_X, task1_test_Y = btrain.get_train_X_Y(traindata=data_task1_test, feature_bankfile=feature_df, task=1)\n",
    "    t1_x_train, t1_x_vali, t1_y_train, t1_y_vali = train_test_split(task1_train_X,np.array(task1_train_Y).ravel(),test_size=cfg.VALIDATION_RATE,random_state=1)\n",
    "    t1_eval_set = [(t1_x_train, t1_y_train), (t1_x_vali, t1_y_vali), (task1_test_X, task1_test_Y)]\n",
    "\n",
    "    methods=['knn','lr', 'xg', 'dt', 'rf', 'gbdt']\n",
    "    # methods=['xg', 'dt', 'rf', 'gbdt']\n",
    "    for method in methods:\n",
    "        funclib.evaluate_2(baslineName=method, X_train_std=t1_x_train, Y_train=t1_y_train, X_test_std=task1_test_X, Y_test=task1_test_Y, type='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2: Loading features, embdding method=unirep\n",
      "step 3: train isEnzyme model\n",
      "knn \t\t0.882325 \t0.889943 \t\t0.875662 \t0.862258 \t0.875882 \t tp: 4407 fp: 545 fn: 704 tn: 4958\n",
      "lr \t\t0.869324 \t0.899914 \t\t0.845418 \t0.819800 \t0.857991 \t tp: 4190 fp: 466 fn: 921 tn: 5037\n",
      "xg \t\t0.866403 \t0.914664 \t\t0.831521 \t0.796909 \t0.851736 \t tp: 4073 fp: 380 fn: 1038 tn: 5123\n",
      "dt \t\t0.815904 \t0.845329 \t\t0.793646 \t0.756016 \t0.798182 \t tp: 3864 fp: 707 fn: 1247 tn: 4796\n",
      "rf \t\t0.887319 \t0.933747 \t\t0.852975 \t0.824496 \t0.875727 \t tp: 4214 fp: 299 fn: 897 tn: 5204\n",
      "gbdt \t\t0.857076 \t0.911778 \t\t0.818880 \t0.778517 \t0.839894 \t tp: 3979 fp: 385 fn: 1132 tn: 5118\n",
      "step 2: Loading features, embdding method=esm0\n",
      "step 3: train isEnzyme model\n",
      "knn \t\t0.813360 \t0.797415 \t\t0.829036 \t0.820974 \t0.809023 \t tp: 4196 fp: 1066 fn: 915 tn: 4437\n",
      "lr \t\t0.760317 \t0.751027 \t\t0.768951 \t0.751321 \t0.751174 \t tp: 3840 fp: 1273 fn: 1271 tn: 4230\n",
      "xg \t\t0.821274 \t0.829034 \t\t0.814660 \t0.792213 \t0.810205 \t tp: 4049 fp: 835 fn: 1062 tn: 4668\n",
      "dt \t\t0.740531 \t0.744350 \t\t0.737351 \t0.702407 \t0.722770 \t tp: 3590 fp: 1233 fn: 1521 tn: 4270\n",
      "rf \t\t0.841342 \t0.869687 \t\t0.819368 \t0.788691 \t0.827211 \t tp: 4031 fp: 604 fn: 1080 tn: 4899\n",
      "gbdt \t\t0.820332 \t0.822984 \t\t0.818005 \t0.798670 \t0.810644 \t tp: 4082 fp: 878 fn: 1029 tn: 4625\n",
      "step 2: Loading features, embdding method=esm33\n",
      "step 3: train isEnzyme model\n",
      "knn \t\t0.813360 \t0.797415 \t\t0.829036 \t0.820974 \t0.809023 \t tp: 4196 fp: 1066 fn: 915 tn: 4437\n",
      "lr \t\t0.760317 \t0.751027 \t\t0.768951 \t0.751321 \t0.751174 \t tp: 3840 fp: 1273 fn: 1271 tn: 4230\n",
      "xg \t\t0.821274 \t0.829034 \t\t0.814660 \t0.792213 \t0.810205 \t tp: 4049 fp: 835 fn: 1062 tn: 4668\n",
      "dt \t\t0.743264 \t0.747819 \t\t0.739483 \t0.704363 \t0.725441 \t tp: 3600 fp: 1214 fn: 1511 tn: 4289\n",
      "rf \t\t0.841342 \t0.869687 \t\t0.819368 \t0.788691 \t0.827211 \t tp: 4031 fp: 604 fn: 1080 tn: 4899\n",
      "gbdt \t\t0.820332 \t0.822984 \t\t0.818005 \t0.798670 \t0.810644 \t tp: 4082 fp: 878 fn: 1029 tn: 4625\n",
      "step 2: Loading features, embdding method=one-hot\n",
      "step 3: train isEnzyme model\n",
      "knn \t\t0.532787 \t0.726190 \t\t0.526464 \t0.047740 \t0.089591 \t tp: 244 fp: 92 fn: 4867 tn: 5411\n",
      "lr \t\t0.657999 \t0.635152 \t\t0.682376 \t0.680884 \t0.657224 \t tp: 3480 fp: 1999 fn: 1631 tn: 3504\n",
      "xg \t\t0.633786 \t0.660042 \t\t0.618999 \t0.493837 \t0.564969 \t tp: 2524 fp: 1300 fn: 2587 tn: 4203\n",
      "dt \t\t0.610703 \t0.608850 \t\t0.612065 \t0.535707 \t0.569942 \t tp: 2738 fp: 1759 fn: 2373 tn: 3744\n",
      "rf \t\t0.657434 \t0.688860 \t\t0.639141 \t0.526316 \t0.596717 \t tp: 2690 fp: 1215 fn: 2421 tn: 4288\n",
      "gbdt \t\t0.638496 \t0.656127 \t\t0.627487 \t0.523772 \t0.582526 \t tp: 2677 fp: 1403 fn: 2434 tn: 4100\n",
      "step 2: Loading features, embdding method=esm32\n",
      "step 3: train isEnzyme model\n",
      "knn \t\t0.813360 \t0.797415 \t\t0.829036 \t0.820974 \t0.809023 \t tp: 4196 fp: 1066 fn: 915 tn: 4437\n",
      "lr \t\t0.760317 \t0.751027 \t\t0.768951 \t0.751321 \t0.751174 \t tp: 3840 fp: 1273 fn: 1271 tn: 4230\n",
      "xg \t\t0.821274 \t0.829034 \t\t0.814660 \t0.792213 \t0.810205 \t tp: 4049 fp: 835 fn: 1062 tn: 4668\n",
      "dt \t\t0.744300 \t0.746149 \t\t0.742733 \t0.710820 \t0.728056 \t tp: 3633 fp: 1236 fn: 1478 tn: 4267\n",
      "rf \t\t0.841342 \t0.869687 \t\t0.819368 \t0.788691 \t0.827211 \t tp: 4031 fp: 604 fn: 1080 tn: 4899\n",
      "gbdt \t\t0.820332 \t0.822984 \t\t0.818005 \t0.798670 \t0.810644 \t tp: 4082 fp: 878 fn: 1029 tn: 4625\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_METHODs = ['unirep', 'esm0', 'esm33', 'one-hot' , 'esm32']\n",
    "for embd_method in EMBEDDING_METHODs:\n",
    "    print(f'step 2: Loading features, embdding method={embd_method}')\n",
    "    feature_df = bcommon.load_data_embedding(embedding_type=embd_method)\n",
    "\n",
    "    print('step 3: train isEnzyme model')\n",
    "    task1_train_X, task1_train_Y = btrain.get_train_X_Y(traindata=data_task1_train, feature_bankfile=feature_df, task=1)\n",
    "    task1_test_X, task1_test_Y = btrain.get_train_X_Y(traindata=data_task1_test_2022, feature_bankfile=feature_df, task=1)\n",
    "    t1_x_train, t1_x_vali, t1_y_train, t1_y_vali = train_test_split(task1_train_X,np.array(task1_train_Y).ravel(),test_size=cfg.VALIDATION_RATE,random_state=1)\n",
    "    t1_eval_set = [(t1_x_train, t1_y_train), (t1_x_vali, t1_y_vali), (task1_test_X, task1_test_Y)]\n",
    "\n",
    "    methods=['knn','lr', 'xg', 'dt', 'rf', 'gbdt']\n",
    "    # methods=['xg', 'dt', 'rf', 'gbdt']\n",
    "    for method in methods:\n",
    "        funclib.evaluate_2(baslineName=method, X_train_std=t1_x_train, Y_train=t1_y_train, X_test_std=task1_test_X, Y_test=task1_test_Y, type='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'step 2: Loading features, embdding method={embd_method}')\n",
    "feature_df = bcommon.load_data_embedding(embedding_type=embd_method)\n",
    "\n",
    "print('step 3: train isEnzyme model')\n",
    "task1_train_X, task1_train_Y = btrain.get_train_X_Y(traindata=data_task1_train, feature_bankfile=feature_df, task=1)\n",
    "task1_test_X, task1_test_Y = btrain.get_train_X_Y(traindata=data_task1_test, feature_bankfile=feature_df, task=1)\n",
    "t1_x_train, t1_x_vali, t1_y_train, t1_y_vali = train_test_split(task1_train_X,np.array(task1_train_Y).ravel(),test_size=cfg.VALIDATION_RATE,random_state=1)\n",
    "t1_eval_set = [(t1_x_train, t1_y_train), (t1_x_vali, t1_y_vali), (task1_test_X, task1_test_Y)]\n",
    "\n",
    "methods=['knn','lr', 'xg', 'dt', 'rf', 'gbdt']\n",
    "# methods=['xg', 'dt', 'rf', 'gbdt']\n",
    "for method in methods:\n",
    "    funclib.evaluate_2(baslineName=method, X_train_std=t1_x_train, Y_train=t1_y_train, X_test_std=task1_test_X, Y_test=task1_test_Y, type='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f1271</th>\n",
       "      <th>f1272</th>\n",
       "      <th>f1273</th>\n",
       "      <th>f1274</th>\n",
       "      <th>f1275</th>\n",
       "      <th>f1276</th>\n",
       "      <th>f1277</th>\n",
       "      <th>f1278</th>\n",
       "      <th>f1279</th>\n",
       "      <th>f1280</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P84233</td>\n",
       "      <td>-0.146607</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.023837</td>\n",
       "      <td>0.032904</td>\n",
       "      <td>-0.007226</td>\n",
       "      <td>0.019266</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>-0.056562</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076818</td>\n",
       "      <td>-0.100577</td>\n",
       "      <td>-0.017798</td>\n",
       "      <td>0.084299</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>0.097957</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>-0.010846</td>\n",
       "      <td>0.083537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0A7F3</td>\n",
       "      <td>-0.198304</td>\n",
       "      <td>0.008354</td>\n",
       "      <td>0.019647</td>\n",
       "      <td>0.029310</td>\n",
       "      <td>-0.018305</td>\n",
       "      <td>0.045471</td>\n",
       "      <td>0.075197</td>\n",
       "      <td>-0.044946</td>\n",
       "      <td>-0.003504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057923</td>\n",
       "      <td>-0.086899</td>\n",
       "      <td>-0.014135</td>\n",
       "      <td>0.082852</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.123944</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.069839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P03212</td>\n",
       "      <td>-0.198705</td>\n",
       "      <td>0.011568</td>\n",
       "      <td>0.028825</td>\n",
       "      <td>0.039880</td>\n",
       "      <td>-0.014772</td>\n",
       "      <td>0.022454</td>\n",
       "      <td>0.045277</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053603</td>\n",
       "      <td>-0.093371</td>\n",
       "      <td>-0.010378</td>\n",
       "      <td>0.082583</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>0.104650</td>\n",
       "      <td>0.023149</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>-0.015051</td>\n",
       "      <td>0.070366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P01158</td>\n",
       "      <td>0.429650</td>\n",
       "      <td>0.021301</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.021442</td>\n",
       "      <td>-0.042830</td>\n",
       "      <td>-0.407126</td>\n",
       "      <td>-0.226068</td>\n",
       "      <td>0.249569</td>\n",
       "      <td>-0.051777</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001685</td>\n",
       "      <td>-0.192207</td>\n",
       "      <td>0.037732</td>\n",
       "      <td>-0.007199</td>\n",
       "      <td>0.187262</td>\n",
       "      <td>0.146447</td>\n",
       "      <td>0.024233</td>\n",
       "      <td>-0.028932</td>\n",
       "      <td>0.168984</td>\n",
       "      <td>0.008123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P0A6U4</td>\n",
       "      <td>-0.120271</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.017928</td>\n",
       "      <td>0.021672</td>\n",
       "      <td>-0.045205</td>\n",
       "      <td>0.112135</td>\n",
       "      <td>-0.020785</td>\n",
       "      <td>0.029727</td>\n",
       "      <td>-0.018858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>-0.082027</td>\n",
       "      <td>-0.018403</td>\n",
       "      <td>0.026921</td>\n",
       "      <td>0.032905</td>\n",
       "      <td>0.038215</td>\n",
       "      <td>0.009250</td>\n",
       "      <td>-0.001736</td>\n",
       "      <td>-0.123505</td>\n",
       "      <td>0.047905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499435</th>\n",
       "      <td>A5WW24</td>\n",
       "      <td>-0.016626</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>-0.016473</td>\n",
       "      <td>0.018177</td>\n",
       "      <td>-0.012397</td>\n",
       "      <td>-0.029998</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005417</td>\n",
       "      <td>-0.049407</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.020916</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.023115</td>\n",
       "      <td>-0.000529</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>-0.028188</td>\n",
       "      <td>0.004180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499436</th>\n",
       "      <td>Q7SBA0</td>\n",
       "      <td>-0.192217</td>\n",
       "      <td>-0.003872</td>\n",
       "      <td>0.013206</td>\n",
       "      <td>0.033440</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>-0.059870</td>\n",
       "      <td>0.041330</td>\n",
       "      <td>0.018678</td>\n",
       "      <td>-0.018491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015614</td>\n",
       "      <td>-0.092371</td>\n",
       "      <td>-0.026066</td>\n",
       "      <td>0.078957</td>\n",
       "      <td>0.017766</td>\n",
       "      <td>0.081856</td>\n",
       "      <td>0.024689</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.007449</td>\n",
       "      <td>0.099686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499437</th>\n",
       "      <td>P0DW10</td>\n",
       "      <td>-0.204385</td>\n",
       "      <td>-0.003039</td>\n",
       "      <td>0.014855</td>\n",
       "      <td>0.028831</td>\n",
       "      <td>0.003722</td>\n",
       "      <td>-0.068608</td>\n",
       "      <td>0.051244</td>\n",
       "      <td>0.035182</td>\n",
       "      <td>-0.020905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017614</td>\n",
       "      <td>-0.089416</td>\n",
       "      <td>-0.030291</td>\n",
       "      <td>0.071393</td>\n",
       "      <td>0.028361</td>\n",
       "      <td>0.087015</td>\n",
       "      <td>0.021463</td>\n",
       "      <td>0.003824</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.085389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499438</th>\n",
       "      <td>C9DG80</td>\n",
       "      <td>-0.139306</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>0.018049</td>\n",
       "      <td>0.025205</td>\n",
       "      <td>-0.000576</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.031189</td>\n",
       "      <td>0.036802</td>\n",
       "      <td>-0.026377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018757</td>\n",
       "      <td>-0.103098</td>\n",
       "      <td>-0.020845</td>\n",
       "      <td>0.076714</td>\n",
       "      <td>0.029975</td>\n",
       "      <td>0.126174</td>\n",
       "      <td>0.027243</td>\n",
       "      <td>-0.001471</td>\n",
       "      <td>0.047446</td>\n",
       "      <td>0.096782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499439</th>\n",
       "      <td>C0HM09</td>\n",
       "      <td>-0.243621</td>\n",
       "      <td>0.033530</td>\n",
       "      <td>-0.009153</td>\n",
       "      <td>0.007613</td>\n",
       "      <td>-0.013856</td>\n",
       "      <td>-0.047827</td>\n",
       "      <td>0.075465</td>\n",
       "      <td>-0.013737</td>\n",
       "      <td>-0.028591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045601</td>\n",
       "      <td>-0.085012</td>\n",
       "      <td>-0.000566</td>\n",
       "      <td>0.079849</td>\n",
       "      <td>0.030393</td>\n",
       "      <td>0.102083</td>\n",
       "      <td>0.014632</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>-0.043008</td>\n",
       "      <td>0.109856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499440 rows × 1281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id        f1        f2        f3        f4        f5        f6  \\\n",
       "0       P84233 -0.146607  0.001917  0.023837  0.032904 -0.007226  0.019266   \n",
       "1       P0A7F3 -0.198304  0.008354  0.019647  0.029310 -0.018305  0.045471   \n",
       "2       P03212 -0.198705  0.011568  0.028825  0.039880 -0.014772  0.022454   \n",
       "3       P01158  0.429650  0.021301  0.058200  0.021442 -0.042830 -0.407126   \n",
       "4       P0A6U4 -0.120271  0.002771  0.017928  0.021672 -0.045205  0.112135   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "499435  A5WW24 -0.016626  0.000310  0.004762  0.003728 -0.016473  0.018177   \n",
       "499436  Q7SBA0 -0.192217 -0.003872  0.013206  0.033440  0.000400 -0.059870   \n",
       "499437  P0DW10 -0.204385 -0.003039  0.014855  0.028831  0.003722 -0.068608   \n",
       "499438  C9DG80 -0.139306  0.004557  0.018049  0.025205 -0.000576  0.008378   \n",
       "499439  C0HM09 -0.243621  0.033530 -0.009153  0.007613 -0.013856 -0.047827   \n",
       "\n",
       "              f7        f8        f9  ...     f1271     f1272     f1273  \\\n",
       "0       0.002471 -0.056562  0.004020  ...  0.076818 -0.100577 -0.017798   \n",
       "1       0.075197 -0.044946 -0.003504  ...  0.057923 -0.086899 -0.014135   \n",
       "2       0.045277  0.001027  0.002064  ...  0.053603 -0.093371 -0.010378   \n",
       "3      -0.226068  0.249569 -0.051777  ... -0.001685 -0.192207  0.037732   \n",
       "4      -0.020785  0.029727 -0.018858  ...  0.007001 -0.082027 -0.018403   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "499435 -0.012397 -0.029998 -0.006616  ...  0.005417 -0.049407  0.001244   \n",
       "499436  0.041330  0.018678 -0.018491  ...  0.015614 -0.092371 -0.026066   \n",
       "499437  0.051244  0.035182 -0.020905  ...  0.017614 -0.089416 -0.030291   \n",
       "499438  0.031189  0.036802 -0.026377  ...  0.018757 -0.103098 -0.020845   \n",
       "499439  0.075465 -0.013737 -0.028591  ...  0.045601 -0.085012 -0.000566   \n",
       "\n",
       "           f1274     f1275     f1276     f1277     f1278     f1279     f1280  \n",
       "0       0.084299  0.003090  0.097957  0.004955  0.001013 -0.010846  0.083537  \n",
       "1       0.082852  0.006422  0.123944  0.019837  0.004477  0.002239  0.069839  \n",
       "2       0.082583  0.001769  0.104650  0.023149  0.009615 -0.015051  0.070366  \n",
       "3      -0.007199  0.187262  0.146447  0.024233 -0.028932  0.168984  0.008123  \n",
       "4       0.026921  0.032905  0.038215  0.009250 -0.001736 -0.123505  0.047905  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "499435  0.020916  0.013201  0.023115 -0.000529  0.003491 -0.028188  0.004180  \n",
       "499436  0.078957  0.017766  0.081856  0.024689  0.004242  0.007449  0.099686  \n",
       "499437  0.071393  0.028361  0.087015  0.021463  0.003824  0.001678  0.085389  \n",
       "499438  0.076714  0.029975  0.126174  0.027243 -0.001471  0.047446  0.096782  \n",
       "499439  0.079849  0.030393  0.102083  0.014632  0.003271 -0.043008  0.109856  \n",
       "\n",
       "[499440 rows x 1281 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcommon.load_data_embedding(embedding_type='esm0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f1271</th>\n",
       "      <th>f1272</th>\n",
       "      <th>f1273</th>\n",
       "      <th>f1274</th>\n",
       "      <th>f1275</th>\n",
       "      <th>f1276</th>\n",
       "      <th>f1277</th>\n",
       "      <th>f1278</th>\n",
       "      <th>f1279</th>\n",
       "      <th>f1280</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P84233</td>\n",
       "      <td>-0.146607</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.023837</td>\n",
       "      <td>0.032904</td>\n",
       "      <td>-0.007226</td>\n",
       "      <td>0.019266</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>-0.056562</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076818</td>\n",
       "      <td>-0.100577</td>\n",
       "      <td>-0.017798</td>\n",
       "      <td>0.084299</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>0.097957</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>-0.010846</td>\n",
       "      <td>0.083537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0A7F3</td>\n",
       "      <td>-0.198304</td>\n",
       "      <td>0.008354</td>\n",
       "      <td>0.019647</td>\n",
       "      <td>0.029310</td>\n",
       "      <td>-0.018305</td>\n",
       "      <td>0.045471</td>\n",
       "      <td>0.075197</td>\n",
       "      <td>-0.044946</td>\n",
       "      <td>-0.003504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057923</td>\n",
       "      <td>-0.086899</td>\n",
       "      <td>-0.014135</td>\n",
       "      <td>0.082852</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.123944</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.069839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P03212</td>\n",
       "      <td>-0.198705</td>\n",
       "      <td>0.011568</td>\n",
       "      <td>0.028825</td>\n",
       "      <td>0.039880</td>\n",
       "      <td>-0.014772</td>\n",
       "      <td>0.022454</td>\n",
       "      <td>0.045277</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053603</td>\n",
       "      <td>-0.093371</td>\n",
       "      <td>-0.010378</td>\n",
       "      <td>0.082583</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>0.104650</td>\n",
       "      <td>0.023149</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>-0.015051</td>\n",
       "      <td>0.070366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P01158</td>\n",
       "      <td>0.429650</td>\n",
       "      <td>0.021301</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.021442</td>\n",
       "      <td>-0.042830</td>\n",
       "      <td>-0.407126</td>\n",
       "      <td>-0.226068</td>\n",
       "      <td>0.249569</td>\n",
       "      <td>-0.051777</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001685</td>\n",
       "      <td>-0.192207</td>\n",
       "      <td>0.037732</td>\n",
       "      <td>-0.007199</td>\n",
       "      <td>0.187262</td>\n",
       "      <td>0.146447</td>\n",
       "      <td>0.024233</td>\n",
       "      <td>-0.028932</td>\n",
       "      <td>0.168984</td>\n",
       "      <td>0.008123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P0A6U4</td>\n",
       "      <td>-0.120271</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.017928</td>\n",
       "      <td>0.021672</td>\n",
       "      <td>-0.045205</td>\n",
       "      <td>0.112135</td>\n",
       "      <td>-0.020785</td>\n",
       "      <td>0.029727</td>\n",
       "      <td>-0.018858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>-0.082027</td>\n",
       "      <td>-0.018403</td>\n",
       "      <td>0.026921</td>\n",
       "      <td>0.032905</td>\n",
       "      <td>0.038215</td>\n",
       "      <td>0.009250</td>\n",
       "      <td>-0.001736</td>\n",
       "      <td>-0.123505</td>\n",
       "      <td>0.047905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503248</th>\n",
       "      <td>A5WW24</td>\n",
       "      <td>12.929022</td>\n",
       "      <td>6.188353</td>\n",
       "      <td>-14.868094</td>\n",
       "      <td>-24.106243</td>\n",
       "      <td>-6.759967</td>\n",
       "      <td>-0.711146</td>\n",
       "      <td>2.120794</td>\n",
       "      <td>-14.952251</td>\n",
       "      <td>-2.365670</td>\n",
       "      <td>...</td>\n",
       "      <td>12.572624</td>\n",
       "      <td>7.570918</td>\n",
       "      <td>-14.053569</td>\n",
       "      <td>-8.367974</td>\n",
       "      <td>6.807021</td>\n",
       "      <td>22.575987</td>\n",
       "      <td>4.863638</td>\n",
       "      <td>13.445599</td>\n",
       "      <td>-13.337751</td>\n",
       "      <td>-5.242069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503249</th>\n",
       "      <td>Q7SBA0</td>\n",
       "      <td>-0.403294</td>\n",
       "      <td>4.927026</td>\n",
       "      <td>6.466229</td>\n",
       "      <td>3.745415</td>\n",
       "      <td>-8.426816</td>\n",
       "      <td>-5.004267</td>\n",
       "      <td>-10.816579</td>\n",
       "      <td>-3.676574</td>\n",
       "      <td>-17.562426</td>\n",
       "      <td>...</td>\n",
       "      <td>18.616261</td>\n",
       "      <td>-3.098237</td>\n",
       "      <td>-7.562515</td>\n",
       "      <td>-3.094149</td>\n",
       "      <td>-14.189250</td>\n",
       "      <td>-2.007169</td>\n",
       "      <td>15.152642</td>\n",
       "      <td>-4.724200</td>\n",
       "      <td>-6.876630</td>\n",
       "      <td>14.522579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503250</th>\n",
       "      <td>P0DW10</td>\n",
       "      <td>-0.309852</td>\n",
       "      <td>4.897358</td>\n",
       "      <td>6.892168</td>\n",
       "      <td>3.506357</td>\n",
       "      <td>-9.486552</td>\n",
       "      <td>-5.952254</td>\n",
       "      <td>-10.688879</td>\n",
       "      <td>-3.418377</td>\n",
       "      <td>-15.975063</td>\n",
       "      <td>...</td>\n",
       "      <td>20.828060</td>\n",
       "      <td>-3.560479</td>\n",
       "      <td>-6.202727</td>\n",
       "      <td>-3.415660</td>\n",
       "      <td>-13.150867</td>\n",
       "      <td>-0.568852</td>\n",
       "      <td>16.026691</td>\n",
       "      <td>-4.340854</td>\n",
       "      <td>-8.537683</td>\n",
       "      <td>15.001244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503251</th>\n",
       "      <td>C9DG80</td>\n",
       "      <td>5.572292</td>\n",
       "      <td>1.661716</td>\n",
       "      <td>1.281703</td>\n",
       "      <td>5.881115</td>\n",
       "      <td>-12.469779</td>\n",
       "      <td>-0.236342</td>\n",
       "      <td>-1.271194</td>\n",
       "      <td>0.140252</td>\n",
       "      <td>-6.617912</td>\n",
       "      <td>...</td>\n",
       "      <td>18.437107</td>\n",
       "      <td>-1.917273</td>\n",
       "      <td>3.563461</td>\n",
       "      <td>-5.729240</td>\n",
       "      <td>-24.487797</td>\n",
       "      <td>1.210020</td>\n",
       "      <td>7.129851</td>\n",
       "      <td>0.015560</td>\n",
       "      <td>-4.438664</td>\n",
       "      <td>1.182109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503252</th>\n",
       "      <td>C0HM09</td>\n",
       "      <td>1.678678</td>\n",
       "      <td>10.283772</td>\n",
       "      <td>4.989214</td>\n",
       "      <td>-4.551658</td>\n",
       "      <td>-1.954896</td>\n",
       "      <td>-5.667089</td>\n",
       "      <td>-7.945621</td>\n",
       "      <td>-1.880737</td>\n",
       "      <td>-9.550148</td>\n",
       "      <td>...</td>\n",
       "      <td>11.021955</td>\n",
       "      <td>-1.778591</td>\n",
       "      <td>-5.384731</td>\n",
       "      <td>-9.707513</td>\n",
       "      <td>-11.743762</td>\n",
       "      <td>-3.928432</td>\n",
       "      <td>2.257149</td>\n",
       "      <td>6.232333</td>\n",
       "      <td>6.633601</td>\n",
       "      <td>9.773381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503253 rows × 1281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id         f1         f2         f3         f4         f5  \\\n",
       "0       P84233  -0.146607   0.001917   0.023837   0.032904  -0.007226   \n",
       "1       P0A7F3  -0.198304   0.008354   0.019647   0.029310  -0.018305   \n",
       "2       P03212  -0.198705   0.011568   0.028825   0.039880  -0.014772   \n",
       "3       P01158   0.429650   0.021301   0.058200   0.021442  -0.042830   \n",
       "4       P0A6U4  -0.120271   0.002771   0.017928   0.021672  -0.045205   \n",
       "...        ...        ...        ...        ...        ...        ...   \n",
       "503248  A5WW24  12.929022   6.188353 -14.868094 -24.106243  -6.759967   \n",
       "503249  Q7SBA0  -0.403294   4.927026   6.466229   3.745415  -8.426816   \n",
       "503250  P0DW10  -0.309852   4.897358   6.892168   3.506357  -9.486552   \n",
       "503251  C9DG80   5.572292   1.661716   1.281703   5.881115 -12.469779   \n",
       "503252  C0HM09   1.678678  10.283772   4.989214  -4.551658  -1.954896   \n",
       "\n",
       "              f6         f7         f8         f9  ...      f1271     f1272  \\\n",
       "0       0.019266   0.002471  -0.056562   0.004020  ...   0.076818 -0.100577   \n",
       "1       0.045471   0.075197  -0.044946  -0.003504  ...   0.057923 -0.086899   \n",
       "2       0.022454   0.045277   0.001027   0.002064  ...   0.053603 -0.093371   \n",
       "3      -0.407126  -0.226068   0.249569  -0.051777  ...  -0.001685 -0.192207   \n",
       "4       0.112135  -0.020785   0.029727  -0.018858  ...   0.007001 -0.082027   \n",
       "...          ...        ...        ...        ...  ...        ...       ...   \n",
       "503248 -0.711146   2.120794 -14.952251  -2.365670  ...  12.572624  7.570918   \n",
       "503249 -5.004267 -10.816579  -3.676574 -17.562426  ...  18.616261 -3.098237   \n",
       "503250 -5.952254 -10.688879  -3.418377 -15.975063  ...  20.828060 -3.560479   \n",
       "503251 -0.236342  -1.271194   0.140252  -6.617912  ...  18.437107 -1.917273   \n",
       "503252 -5.667089  -7.945621  -1.880737  -9.550148  ...  11.021955 -1.778591   \n",
       "\n",
       "            f1273     f1274      f1275      f1276      f1277      f1278  \\\n",
       "0       -0.017798  0.084299   0.003090   0.097957   0.004955   0.001013   \n",
       "1       -0.014135  0.082852   0.006422   0.123944   0.019837   0.004477   \n",
       "2       -0.010378  0.082583   0.001769   0.104650   0.023149   0.009615   \n",
       "3        0.037732 -0.007199   0.187262   0.146447   0.024233  -0.028932   \n",
       "4       -0.018403  0.026921   0.032905   0.038215   0.009250  -0.001736   \n",
       "...           ...       ...        ...        ...        ...        ...   \n",
       "503248 -14.053569 -8.367974   6.807021  22.575987   4.863638  13.445599   \n",
       "503249  -7.562515 -3.094149 -14.189250  -2.007169  15.152642  -4.724200   \n",
       "503250  -6.202727 -3.415660 -13.150867  -0.568852  16.026691  -4.340854   \n",
       "503251   3.563461 -5.729240 -24.487797   1.210020   7.129851   0.015560   \n",
       "503252  -5.384731 -9.707513 -11.743762  -3.928432   2.257149   6.232333   \n",
       "\n",
       "            f1279      f1280  \n",
       "0       -0.010846   0.083537  \n",
       "1        0.002239   0.069839  \n",
       "2       -0.015051   0.070366  \n",
       "3        0.168984   0.008123  \n",
       "4       -0.123505   0.047905  \n",
       "...           ...        ...  \n",
       "503248 -13.337751  -5.242069  \n",
       "503249  -6.876630  14.522579  \n",
       "503250  -8.537683  15.001244  \n",
       "503251  -4.438664   1.182109  \n",
       "503252   6.633601   9.773381  \n",
       "\n",
       "[503253 rows x 1281 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcommon.load_data_embedding(embedding_type='esm32')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmlf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) \n[GCC 10.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "01198cbd8e9354c2bdc2e2d750ceaa12955025c4f7059132aa2585625d50e356"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
